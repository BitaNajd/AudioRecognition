
Fold:  0
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
Train for 16 steps, validate for 16 steps
WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.
15/16 [===========================>..] - ETA: 6s - loss: 3.7249 - acc: 0.0214 WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.

Epoch 00001: val_loss improved from inf to 3.72643, saving model to best_0.h5
16/16 [==============================] - 219s 14s/step - loss: 3.7261 - acc: 0.0200 - val_loss: 3.7264 - val_acc: 0.0190
WARNING:tensorflow:From <ipython-input-55-b8e68b833353>:39: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.predict, which supports generators.
WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.
16/16 [==============================] - 197s 12s/step
WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.
WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.
 4/16 [======>.......................] - ETA: 1:34

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-55-b8e68b833353> in <module>
     44                                     preprocessing_fn=audio_norm)
     45     predictions = model.predict_generator(test_generator, use_multiprocessing=True, 
---> 46                                           max_queue_size=20, verbose=1)
     47     np.save(PREDICTION_FOLDER + "/test_predictions_%d.npy"%i, predictions)
     48 

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py in new_func(*args, **kwargs)
    322               'in a future version' if date is None else ('after %s' % date),
    323               instructions)
--> 324       return func(*args, **kwargs)
    325     return tf_decorator.make_decorator(
    326         func, new_func, 'deprecated',

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in predict_generator(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)
   1358         use_multiprocessing=use_multiprocessing,
   1359         verbose=verbose,
-> 1360         callbacks=callbacks)
   1361 
   1362   def _check_call_args(self, method_name):

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1011         max_queue_size=max_queue_size,
   1012         workers=workers,
-> 1013         use_multiprocessing=use_multiprocessing)
   1014 
   1015   def reset_metrics(self):

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in predict(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    496         model, ModeKeys.PREDICT, x=x, batch_size=batch_size, verbose=verbose,
    497         steps=steps, callbacks=callbacks, max_queue_size=max_queue_size,
--> 498         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
    499 
    500 

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in _model_iteration(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    473               mode=mode,
    474               training_context=training_context,
--> 475               total_epochs=1)
    476           cbks.make_logs(model, epoch_logs, result, mode)
    477 

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--> 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---> 98                               distributed_function(input_fn))
     99 
    100   return execution_function

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    604       # In this case we have not created variables on the first call. So we can
    605       # run the first trace but we should fail if variables are created.
--> 606       results = self._stateful_fn(*args, **kwds)
    607       if self._created_variables:
    608         raise ValueError("Creating variables on a non-first call to a function"

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   2361     with self._lock:
   2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 
   2365   @property

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)
   1609          if isinstance(t, (ops.Tensor,
   1610                            resource_variable_ops.BaseResourceVariable))),
-> 1611         self.captured_inputs)
   1612 
   1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1690       # No tape is watching; skip to running the function.
   1691       return self._build_call_outputs(self._inference_function.call(
-> 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(
   1694         args,

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    543               inputs=args,
    544               attrs=("executor_type", executor_type, "config_proto", config),
--> 545               ctx=ctx)
    546         else:
    547           outputs = execute.execute_with_cancellation(

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~/anaconda3/envs/backpack1/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError:  ValueError: Input signal length=0 is too small to resample from 44100->100
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/multiprocessing/pool.py", line 121, in worker
    result = (True, func(*args, **kwds))
  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py", line 663, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File "<ipython-input-54-ca56e0eff938>", line 19, in __getitem__
    return self.__data_generation(list_IDs_temp)
  File "<ipython-input-54-ca56e0eff938>", line 34, in __data_generation
    res_type='kaiser_fast')
  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/librosa/core/audio.py", line 171, in load
    y = resample(y, sr_native, sr, res_type=res_type)
  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/librosa/core/audio.py", line 547, in resample
    y_hat = resampy.resample(y, orig_sr, target_sr, filter=res_type, axis=-1)
  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/resampy/core.py", line 98, in resample
    'resample from {}->{}'.format(x.shape[axis], sr_orig, sr_new))
ValueError: Input signal length=0 is too small to resample from 44100->100
"""


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py", line 236, in __call__
    ret = func(*args)

  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py", line 789, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py", line 889, in wrapped_generator
    for batch in generator_fn():

  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py", line 881, in get
    six.reraise(*sys.exc_info())

  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/six.py", line 703, in reraise
    raise value

  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py", line 875, in get
    inputs = self.queue.get(block=True).get()

  File "/home/bita/anaconda3/envs/backpack1/lib/python3.7/multiprocessing/pool.py", line 657, in get
    raise self._value

ValueError: Input signal length=0 is too small to resample from 44100->100


	 [[{{node PyFunc}}]]
	 [[IteratorGetNext]] [Op:__inference_distributed_function_1657]

Function call stack:
distributed_function



